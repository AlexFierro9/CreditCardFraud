{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 23498,
          "sourceType": "datasetVersion",
          "datasetId": 310
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 204.597825,
      "end_time": "2025-01-10T12:20:04.437521",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-01-10T12:16:39.839696",
      "version": "2.6.0"
    },
    "colab": {
      "name": "it's done🥳🙌🥲☠️😔🥂",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "organizations_mlg_ulb_creditcardfraud_path = kagglehub.dataset_download('organizations/mlg-ulb/creditcardfraud')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "iQD-pU8lhBXT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pykan torch-optimizer shap lime --quiet\n",
        "import pandas as pd\n",
        "import sklearn.metrics as metrique\n",
        "from pandas import Series\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import kan"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 13.413436,
          "end_time": "2025-01-10T12:16:55.461064",
          "exception": false,
          "start_time": "2025-01-10T12:16:42.047628",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:02:16.568706Z",
          "iopub.execute_input": "2025-03-13T18:02:16.56898Z",
          "iopub.status.idle": "2025-03-13T18:02:26.887487Z",
          "shell.execute_reply.started": "2025-03-13T18:02:16.568948Z",
          "shell.execute_reply": "2025-03-13T18:02:26.886486Z"
        },
        "id": "RXftHi5rhBXV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r\"/kaggle/input/creditcardfraud/creditcard.csv\")\n",
        "data"
      ],
      "metadata": {
        "papermill": {
          "duration": 3.208617,
          "end_time": "2025-01-10T12:16:58.673627",
          "exception": false,
          "start_time": "2025-01-10T12:16:55.46501",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:02:26.892508Z",
          "iopub.execute_input": "2025-03-13T18:02:26.892827Z",
          "iopub.status.idle": "2025-03-13T18:02:30.540759Z",
          "shell.execute_reply.started": "2025-03-13T18:02:26.892792Z",
          "shell.execute_reply": "2025-03-13T18:02:30.539878Z"
        },
        "id": "fijw0Tu-hBXV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "oversample = ADASYN()\n",
        "X = data.drop(['Class'], axis = 'columns')\n",
        "y = data['Class']\n",
        "X, y = oversample.fit_resample(X, data['Class'])"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023692,
          "end_time": "2025-01-10T12:16:58.701274",
          "exception": false,
          "start_time": "2025-01-10T12:16:58.677582",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:02:30.541682Z",
          "iopub.execute_input": "2025-03-13T18:02:30.542Z",
          "iopub.status.idle": "2025-03-13T18:02:31.941459Z",
          "shell.execute_reply.started": "2025-03-13T18:02:30.541969Z",
          "shell.execute_reply": "2025-03-13T18:02:31.940739Z"
        },
        "id": "dV-n337JhBXW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.039255,
          "end_time": "2025-01-10T12:16:58.744203",
          "exception": false,
          "start_time": "2025-01-10T12:16:58.704948",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:02:31.94269Z",
          "iopub.execute_input": "2025-03-13T18:02:31.942954Z",
          "iopub.status.idle": "2025-03-13T18:02:32.006459Z",
          "shell.execute_reply.started": "2025-03-13T18:02:31.942922Z",
          "shell.execute_reply": "2025-03-13T18:02:32.005612Z"
        },
        "id": "8wYuYAxshBXW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
        "scaler = RobustScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "print(type(y_train))\n",
        "print(type(y_test))\n",
        "\n",
        "y_train = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
        "y_test = y_test.values if isinstance(y_test, pd.Series) else y_test\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "\n",
        "for X_batch, y_batch in train_loader:\n",
        "    print(f\"Batch X shape: {X_batch.shape}, Batch y shape: {y_batch.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.810714,
          "end_time": "2025-01-10T12:16:59.558671",
          "exception": false,
          "start_time": "2025-01-10T12:16:58.747957",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:02:34.469426Z",
          "iopub.execute_input": "2025-03-13T18:02:34.469757Z",
          "iopub.status.idle": "2025-03-13T18:02:35.1361Z",
          "shell.execute_reply.started": "2025-03-13T18:02:34.469731Z",
          "shell.execute_reply": "2025-03-13T18:02:35.135332Z"
        },
        "id": "eHJquRCrhBXW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearAttention, self).__init__()\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def elu_feature_map(self, x):\n",
        "        return F.elu(x) + 1\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        Q = self.elu_feature_map(Q)\n",
        "        K = self.elu_feature_map(K)\n",
        "        KV = torch.einsum(\"nsd,nsd->ns\", K, V)\n",
        "        # Compute the normalizer\n",
        "        Z = 1/(torch.einsum(\"nld,nd->nl\", Q, K.sum(dim=1))+self.eps)\n",
        "        # Finally compute and return the new values\n",
        "        V = torch.einsum(\"nld,ns,nl->nd\", Q, KV, Z)\n",
        "        return V.contiguous()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01039,
          "end_time": "2025-01-10T12:16:59.573262",
          "exception": false,
          "start_time": "2025-01-10T12:16:59.562872",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:02:37.053942Z",
          "iopub.execute_input": "2025-03-13T18:02:37.054278Z",
          "iopub.status.idle": "2025-03-13T18:02:37.059353Z",
          "shell.execute_reply.started": "2025-03-13T18:02:37.054251Z",
          "shell.execute_reply": "2025-03-13T18:02:37.058577Z"
        },
        "id": "xVnCTqzQhBXX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class LTACNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(LTACNN, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
        "        self.attention_layer = LinearAttention()\n",
        "        self.fc = nn.Linear(241, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x_cnn = x.permute(0, 2, 1)\n",
        "        out_cnn = self.cnn(x_cnn)\n",
        "        out_cnn = out_cnn.reshape(out_cnn.size(0), -1)\n",
        "\n",
        "\n",
        "        x_lstm = x\n",
        "        out_lstm, _ = self.lstm(x_lstm)\n",
        "\n",
        "\n",
        "        out_lstm_last = out_lstm[:, -1, :] if out_lstm.dim() == 3 else out_lstm\n",
        "\n",
        "\n",
        "        combined = torch.cat((out_cnn, out_lstm_last), dim=1)\n",
        "        attention_combined = self.attention_layer(combined.unsqueeze(1), combined.unsqueeze(1), combined.unsqueeze(1))\n",
        "\n",
        "\n",
        "\n",
        "        out = self.fc(attention_combined)\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011425,
          "end_time": "2025-01-10T12:16:59.588414",
          "exception": false,
          "start_time": "2025-01-10T12:16:59.576989",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:06:22.285901Z",
          "iopub.execute_input": "2025-03-13T18:06:22.286313Z",
          "iopub.status.idle": "2025-03-13T18:06:22.295352Z",
          "shell.execute_reply.started": "2025-03-13T18:06:22.286279Z",
          "shell.execute_reply": "2025-03-13T18:06:22.294203Z"
        },
        "id": "uvyw_ToMhBXX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "import torch.optim as optim\n",
        "input_size = X_train.shape[-1]\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "LTACNN = LTACNN(input_size=input_size, hidden_size=1, num_classes=2)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_optimizer import Ranger\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.319516,
          "end_time": "2025-01-10T12:16:59.912103",
          "exception": false,
          "start_time": "2025-01-10T12:16:59.592587",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:06:25.235659Z",
          "iopub.execute_input": "2025-03-13T18:06:25.23595Z",
          "iopub.status.idle": "2025-03-13T18:06:25.249344Z",
          "shell.execute_reply.started": "2025-03-13T18:06:25.235928Z",
          "shell.execute_reply": "2025-03-13T18:06:25.248711Z"
        },
        "id": "FQu5u9JahBXY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_metrics(performance_metrics, epochs):\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    metrics = ['loss', 'roc_auc', 'precision', 'recall','test_roc_auc', 'test_recall', 'test_precision']\n",
        "\n",
        "    for metric in metrics:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for model_name, history in performance_metrics.items():\n",
        "            plt.plot(range(1, epochs+1), history[metric], label=model_name)\n",
        "\n",
        "        plt.title(f'Comparison of {metric.capitalize()} Across Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.320094,
          "end_time": "2025-01-10T12:20:01.03366",
          "exception": false,
          "start_time": "2025-01-10T12:20:00.713566",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:06:26.603907Z",
          "iopub.execute_input": "2025-03-13T18:06:26.604253Z",
          "iopub.status.idle": "2025-03-13T18:06:26.609623Z",
          "shell.execute_reply.started": "2025-03-13T18:06:26.604227Z",
          "shell.execute_reply": "2025-03-13T18:06:26.608707Z"
        },
        "id": "CjIenH2LhBXY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from kan import *\n",
        "class kan_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(kan_model, self).__init__()\n",
        "        self.kan = KAN(width=[30, 60, 120, 241, 1], grid=6, k=8, seed=42)\n",
        "        self.kan.speed()\n",
        "        self.kan.save_act = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(-1)\n",
        "        out = self.kan(x)\n",
        "        return torch.sigmoid(out)\n",
        "kan_model = kan_model()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:06:27.787557Z",
          "iopub.execute_input": "2025-03-13T18:06:27.787858Z",
          "iopub.status.idle": "2025-03-13T18:06:28.800463Z",
          "shell.execute_reply.started": "2025-03-13T18:06:27.787836Z",
          "shell.execute_reply": "2025-03-13T18:06:28.799555Z"
        },
        "id": "6WtDlIGehBXZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred_probs):\n",
        "    \"\"\"Calculate ROC-AUC, Precision, and Recall from ground truth labels and predicted probabilities.\"\"\"\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
        "    binary_preds = [1 if p >= 0.5 else 0 for p in y_pred_probs]\n",
        "    precision = precision_score(y_true, binary_preds)\n",
        "    recall = recall_score(y_true, binary_preds)\n",
        "    return roc_auc, precision, recall\n",
        "\n",
        "# Training function\n",
        "def train_model_on_gpu(model, train_loader, test_loader=None, epochs=10, device=\"cuda\"):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Use Adam optimizer\n",
        "    criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "\n",
        "    history = {'roc_auc': [], 'precision': [], 'recall': [], 'loss': [], 'test_roc_auc': [], 'test_precision': [], 'test_recall': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        all_labels, all_preds, epoch_losses = [], [], []\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device).float()  # Ensure labels are float\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x)  # Get predictions\n",
        "            y_pred = y_pred.squeeze()  # Ensure correct shape for BCELoss\n",
        "\n",
        "            loss = criterion(y_pred, y)  # Compute loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "            all_preds.extend(y_pred.detach().cpu().numpy())\n",
        "\n",
        "        avg_loss = np.mean(epoch_losses)\n",
        "        history['loss'].append(avg_loss)\n",
        "        roc_auc, precision, recall = calculate_metrics(all_labels, all_preds)\n",
        "        history['roc_auc'].append(roc_auc)\n",
        "        history['precision'].append(precision)\n",
        "        history['recall'].append(recall)\n",
        "\n",
        "        print(f\"[{model.__class__.__name__} | Epoch {epoch+1}/{epochs}] Loss: {avg_loss:.4f} | ROC-AUC: {roc_auc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
        "\n",
        "        # Evaluate on test data\n",
        "        if test_loader:\n",
        "            model.eval()\n",
        "            test_labels, test_preds = [], []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for x_test, y_test in test_loader:\n",
        "                    x_test, y_test = x_test.to(device), y_test.to(device).float()\n",
        "                    y_test_pred = model(x_test)\n",
        "\n",
        "                    y_test_pred = y_test_pred.squeeze()\n",
        "                    test_labels.extend(y_test.cpu().numpy())\n",
        "                    test_preds.extend(y_test_pred.cpu().numpy())\n",
        "\n",
        "            test_roc_auc, test_precision, test_recall = calculate_metrics(test_labels, test_preds)\n",
        "            history['test_roc_auc'].append(test_roc_auc)\n",
        "            history['test_precision'].append(test_precision)\n",
        "            history['test_recall'].append(test_recall)\n",
        "\n",
        "            print(f\"[{model.__class__.__name__} | Test | Epoch {epoch+1}/{epochs}] ROC-AUC: {test_roc_auc:.4f} | Precision: {test_precision:.4f} | Recall: {test_recall:.4f}\")\n",
        "            model.train()\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def train(models, train_loader, test_loader=None, epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    result_dict = {}\n",
        "\n",
        "    for model in models:\n",
        "        print(f\"Training model: {model.__class__.__name__}\")\n",
        "        history = train_model_on_gpu(model, train_loader, test_loader, epochs, device)\n",
        "        result_dict[model.__class__.__name__] = history\n",
        "\n",
        "    return result_dict"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:06:29.212946Z",
          "iopub.execute_input": "2025-03-13T18:06:29.213299Z",
          "iopub.status.idle": "2025-03-13T18:06:29.224024Z",
          "shell.execute_reply.started": "2025-03-13T18:06:29.213272Z",
          "shell.execute_reply": "2025-03-13T18:06:29.223092Z"
        },
        "id": "4cX5msW_hBXZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train([kan_model, LTACNN], train_loader,test_loader, 15)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:11:37.02529Z",
          "iopub.execute_input": "2025-03-13T18:11:37.025596Z",
          "execution_failed": "2025-03-13T18:11:58.42Z"
        },
        "id": "hUHGdZh5hBXZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(metrics, 15)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-13T18:11:58.421Z"
        },
        "id": "hCe860ZIhBXa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def evaluate(models, test_loader: DataLoader, device=None):\n",
        "    \"\"\"Evaluates multiple models on a test set and returns performance metrics.\"\"\"\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cuda\")\n",
        "\n",
        "    performance_metrics = {}\n",
        "\n",
        "    for model in models:\n",
        "        print(f\"Evaluating model: {model.__class__.__name__}\")\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        history = {'roc_auc': [], 'precision': [], 'recall': [], 'loss': []}\n",
        "\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        test_losses = []\n",
        "\n",
        "\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "\n",
        "                y_pred = model(x)\n",
        "\n",
        "                y_pred = y_pred.squeeze()\n",
        "\n",
        "\n",
        "                loss = criterion(y_pred, y.float())\n",
        "                test_losses.append(loss.item())\n",
        "\n",
        "\n",
        "                all_labels.extend(y.cpu().numpy())\n",
        "                all_preds.extend(y_pred.cpu().numpy())\n",
        "\n",
        "\n",
        "        avg_loss = np.mean(test_losses)\n",
        "        history['loss'].append(avg_loss)\n",
        "\n",
        "        roc_auc = roc_auc_score(all_labels, all_preds)\n",
        "        history['roc_auc'].append(roc_auc)\n",
        "\n",
        "\n",
        "        binary_preds = [1 if p >= 0.5 else 0 for p in all_preds]\n",
        "        precision = precision_score(all_labels, binary_preds)\n",
        "        recall = recall_score(all_labels, binary_preds)\n",
        "\n",
        "        history['precision'].append(precision)\n",
        "        history['recall'].append(recall)\n",
        "\n",
        "        print(f\"[{model.__class__.__name__} | Test] Loss: {avg_loss:.4f}, ROC-AUC: {roc_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "        performance_metrics[model.__class__.__name__] = history\n",
        "\n",
        "    return performance_metrics\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-13T18:11:58.421Z"
        },
        "id": "kmbZWTVChBXa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = evaluate([LTACNN, kan_model], test_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:11:10.655201Z",
          "iopub.execute_input": "2025-03-13T18:11:10.655507Z",
          "iopub.status.idle": "2025-03-13T18:11:37.024112Z",
          "shell.execute_reply.started": "2025-03-13T18:11:10.655481Z",
          "shell.execute_reply": "2025-03-13T18:11:37.023215Z"
        },
        "id": "N6BUvVlthBXa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import shap\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr, wilcoxon\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"LTACNN\": LTACNN,\n",
        "    \"KAN\": kan_model,\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "num_samples = 1000\n",
        "random_indices_train = torch.randperm(X_train.shape[0])[:num_samples]\n",
        "random_indices_test = torch.randperm(X_test.shape[0])[:num_samples]\n",
        "\n",
        "X_train_sample = X_train[random_indices_train].clone().detach().cpu()\n",
        "X_test_sample = X_test[random_indices_test].clone().detach().cpu()\n",
        "\n",
        "\n",
        "X_train_np = X_train_sample.numpy()\n",
        "X_test_np = X_test_sample.numpy()\n",
        "\n",
        "\n",
        "shap_values_dict = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.to(\"cpu\").eval()\n",
        "\n",
        "\n",
        "    explainer = shap.DeepExplainer(model, X_train_sample)\n",
        "    shap_values = explainer.shap_values(X_test_sample, check_additivity=False)\n",
        "    X_test_flattened = X_test_sample.reshape(X_test_sample.shape[0], -1)\n",
        "\n",
        "\n",
        "    shap_values_flattened = np.array(shap_values).reshape(shap_values.shape[0], -1)\n",
        "\n",
        "\n",
        "    shap_values_dict[name] = shap_values_flattened\n",
        "\n",
        "\n",
        "    shap.summary_plot(shap_values_flattened, X_test_flattened.numpy(), show=False)\n",
        "    plt.title(f\"SHAP Summary Plot - {name}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "shap_df = pd.DataFrame({\n",
        "    \"Feature\": [f\"F{i}\" for i in range(X_test_np.shape[1])]\n",
        "})\n",
        "\n",
        "for name in models.keys():\n",
        "    shap_df[name] = np.mean(np.abs(shap_values_dict[name]), axis=0)\n",
        "\n",
        "print(shap_df.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T18:10:36.803257Z",
          "iopub.status.idle": "2025-03-13T18:10:36.803627Z",
          "shell.execute_reply": "2025-03-13T18:10:36.803463Z"
        },
        "id": "XrVUfr5NhBXa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train_np shape:\", X_train_np.shape)\n",
        "num_features = X_train_np.shape[1]\n",
        "feature_names = [f\"F{i}\" for i in range(num_features)]\n",
        "print(\"Number of features:\", num_features)\n",
        "print(\"Feature names:\", feature_names)\n",
        "X_train_np = X_train_np.reshape(num_samples, -1)\n",
        "print(\"X_train_np shape:\", X_train_np.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T16:30:10.176737Z",
          "iopub.status.idle": "2025-03-13T16:30:10.177051Z",
          "shell.execute_reply": "2025-03-13T16:30:10.176916Z"
        },
        "id": "i9X714IbhBXb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_train_np, feature_names=shap_df[\"Feature\"].values, mode=\"regression\")\n",
        "\n",
        "\n",
        "lime_values_dict = {}\n",
        "X_test_np = X_test_np.reshape(num_samples, -1)\n",
        "for name, model in models.items():\n",
        "    exp = explainer.explain_instance(\n",
        "        X_test_np[0],\n",
        "\n",
        "        lambda x: model(\n",
        "            torch.tensor(x, dtype=torch.float32)\n",
        "                 .unsqueeze(-1)\n",
        "        ).detach().cpu().numpy(),\n",
        "        num_features=X_train_np.shape[1]\n",
        "    )\n",
        "\n",
        "\n",
        "    lime_values_dict[name] = dict(exp.as_list())\n",
        "\n",
        "\n",
        "lime_df = pd.DataFrame(lime_values_dict).fillna(0)\n",
        "lime_df[\"Feature\"] = shap_df[\"Feature\"]\n",
        "\n",
        "print(lime_df.head())\n",
        "\n",
        "\n",
        "shap_melted = shap_df.melt(id_vars=\"Feature\", var_name=\"Model\", value_name=\"SHAP Value\")\n",
        "lime_melted = lime_df.melt(id_vars=\"Feature\", var_name=\"Model\", value_name=\"LIME Value\")\n",
        "lime_df = lime_df.reset_index().rename(columns={\"index\": \"Rule\"})\n",
        "lime_melted_rules = lime_df.melt(id_vars=\"Rule\", var_name=\"Model\", value_name=\"LIME Value\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T16:30:10.178143Z",
          "iopub.status.idle": "2025-03-13T16:30:10.178465Z",
          "shell.execute_reply": "2025-03-13T16:30:10.178355Z"
        },
        "id": "JZEQL2FYhBXb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"Feature\", y=\"SHAP Value\", hue=\"Model\", data=shap_melted)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"SHAP Feature Importance Across Models\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T16:30:10.179173Z",
          "iopub.status.idle": "2025-03-13T16:30:10.179438Z",
          "shell.execute_reply": "2025-03-13T16:30:10.179334Z"
        },
        "id": "Xi3q55achBXb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shap_df:\")\n",
        "print(shap_df.head())\n",
        "print(\"lime_df:\")\n",
        "print(lime_df.head())\n",
        "print(\"lime_melted:\")\n",
        "print(lime_melted.head())\n",
        "print(\"lime_melted columns:\", lime_melted.columns)\n",
        "print(\"lime_melted shape:\", lime_melted.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T16:30:10.180252Z",
          "iopub.status.idle": "2025-03-13T16:30:10.180641Z",
          "shell.execute_reply": "2025-03-13T16:30:10.180474Z"
        },
        "id": "HVJa3Ld9hBXb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(24, 6))\n",
        "sns.barplot(x=\"Rule\", y=\"LIME Value\", hue=\"Model\", data=lime_melted_rules)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"LIME Rule Importance Across Models\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T16:30:10.181557Z",
          "iopub.status.idle": "2025-03-13T16:30:10.181956Z",
          "shell.execute_reply": "2025-03-13T16:30:10.18177Z"
        },
        "id": "1eXp2x9fhBXb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_feature(rule):\n",
        "\n",
        "    m = re.search(r'(F\\d+)', rule)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "lime_df['Feature'] = lime_df['Rule'].apply(extract_feature)\n",
        "\n",
        "print(\"lime_df after extracting 'Feature':\")\n",
        "print(lime_df.head())\n",
        "\n",
        "\n",
        "numeric_cols = ['LTACNN', 'kan_model']\n",
        "\n",
        "lime_df_grouped = lime_df.groupby('Feature')[numeric_cols].mean().reset_index()\n",
        "\n",
        "print(\"\\nAggregated LIME DataFrame (lime_df_grouped):\")\n",
        "print(lime_df_grouped.head())\n",
        "\n",
        "merged_df = shap_df.set_index(\"Feature\").join(\n",
        "    lime_df_grouped.set_index(\"Feature\"), lsuffix=\"_SHAP\", rsuffix=\"_LIME\"\n",
        ")\n",
        "\n",
        "\n",
        "merged_df_numeric = merged_df.select_dtypes(include=[\"number\"])\n",
        "\n",
        "\n",
        "print(\"\\nMerged DataFrame (numeric only):\")\n",
        "print(merged_df_numeric.head())\n",
        "\n",
        "\n",
        "corr_matrix = merged_df_numeric.corr(method=\"spearman\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Spearman Correlation of SHAP & LIME Across Models\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T16:30:10.1827Z",
          "iopub.status.idle": "2025-03-13T16:30:10.183091Z",
          "shell.execute_reply": "2025-03-13T16:30:10.182905Z"
        },
        "id": "IcmB4mo5hBXb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for m1, m2 in [(\"LTACNN\", \"kan_model\")]:\n",
        "    print(f\"Wilcoxon Test (SHAP {m1} vs {m2}):\", wilcoxon(shap_df[m1], shap_df[m2]))\n",
        "    print(f\"Wilcoxon Test (LIME {m1} vs {m2}):\", wilcoxon(lime_df[m1], lime_df[m2]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T16:30:10.183872Z",
          "iopub.status.idle": "2025-03-13T16:30:10.184192Z",
          "shell.execute_reply": "2025-03-13T16:30:10.184031Z"
        },
        "id": "Q_zz_JnzhBXc"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}